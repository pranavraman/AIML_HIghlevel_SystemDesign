{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e3a1b59",
   "metadata": {},
   "source": [
    "### ML System Design Notes for Predicting App Usage on iPhone\n",
    "\n",
    "This section provides a concise overview of designing a machine learning (ML) system to predict the first app a user opens on their iPhone after unlocking, targeting 90% accuracy within 100 milliseconds. The notes are tailored for beginners but maintain technical accuracy, covering key components like data management, feature engineering, model selection, and deployment using AWS services. For a comprehensive understanding, refer to the detailed notes below.\n",
    "\n",
    "**Key Points**:\n",
    "- The system aims to predict the first app opened with 90% accuracy in real-time (100 ms).\n",
    "- It seems likely that user behavior data (e.g., app usage, time, location) and contextual signals drive personalized predictions.\n",
    "- AWS services like SageMaker, DynamoDB, and Kinesis are commonly used for scalable ML systems.\n",
    "- Privacy and low latency are critical, requiring data anonymization and optimized inference.\n",
    "- Model choices (e.g., LightGBM, transformers) involve trade-offs between speed and sequential data handling.\n",
    "\n",
    "#### Problem Overview\n",
    "The goal is to build an ML system that predicts the most likely app a user will open after unlocking their iPhone. The system must deliver predictions quickly, personalize based on user habits, and work offline with cached data. Privacy is ensured by anonymizing sensitive data like user IDs and locations.\n",
    "\n",
    "#### Core Components\n",
    "- **Data**: Collect app usage, time, location, and device status; store real-time data in DynamoDB and historical data in S3.\n",
    "- **Features**: Include time since last app use, app switch patterns, and historical usage frequency.\n",
    "- **Model**: LightGBM for speed or transformers for sequential data, validated to achieve 90% accuracy.\n",
    "- **Deployment**: Use SageMaker for real-time inference, with API Gateway and Lambda for request handling.\n",
    "- **Monitoring**: Log feedback (e.g., ignored suggestions) to retrain models if accuracy drops.\n",
    "\n",
    "#### Why AWS?\n",
    "AWS services like SageMaker ([Amazon SageMaker](https://aws.amazon.com/sagemaker/)) simplify ML model training and deployment, while Kinesis and DynamoDB support real-time data processing, ensuring scalability and low latency.\n",
    "\n",
    "---\n",
    "\n",
    "### Detailed ML System Design Notes\n",
    "\n",
    "These notes provide a comprehensive guide to designing an ML system for predicting the first app a user opens on their iPhone after unlocking, targeting 90% accuracy within 100 milliseconds. The content is structured for clarity, using Markdown, and includes definitions, examples, code snippets, and flowcharts. It addresses all key questions from the lecture transcription, tailored for freshers but maintaining technical depth. AWS services are emphasized, and privacy, scalability, and cost-effectiveness are prioritized.\n",
    "\n",
    "#### Introduction to ML System Design\n",
    "\n",
    "**Definition**: ML system design involves creating architectures to develop, deploy, and maintain ML models in production. It integrates machine learning, software engineering, data engineering, and cloud computing to deliver scalable, efficient, and reliable systems.\n",
    "\n",
    "**Importance**: Real-world ML applications, like app usage prediction, require systems that balance accuracy, speed, and scalability. This involves managing data pipelines, selecting appropriate models, and ensuring robust deployment.\n",
    "\n",
    "**Key Concepts**:\n",
    "- **Functional Requirements**: Define what the system does (e.g., predict an app with 90% accuracy).\n",
    "- **Non-Functional Requirements**: Specify performance criteria (e.g., low latency, high availability).\n",
    "- **ML Lifecycle**: Encompasses data ingestion, feature engineering, training, validation, deployment, and monitoring.\n",
    "\n",
    "#### Problem Understanding\n",
    "\n",
    "**Problem Statement**: The system predicts the most likely app a user will open after unlocking their iPhone, achieving 90% accuracy within 100 ms. Predictions must be personalized, work offline, and protect user privacy.\n",
    "\n",
    "**Functional Requirements**:\n",
    "- **Real-time Prediction**: Deliver predictions within 100 ms.\n",
    "- **Personalization**: Use user habits (e.g., time, location) for tailored predictions.\n",
    "- **Offline Availability**: Support predictions with cached data (up to 24 hours old).\n",
    "- **Privacy**: Anonymize sensitive data (e.g., GPS, user IDs).\n",
    "\n",
    "**Non-Functional Requirements**:\n",
    "- **Low Latency**: Ensure predictions within 100 ms.\n",
    "- **Scalability**: Handle millions of devices (thousands of requests per second).\n",
    "- **High Availability**: Achieve 99.9% uptime.\n",
    "- **Security**: Encrypt data at rest and in transit.\n",
    "- **Cost-Effectiveness**: Keep prediction costs low (e.g., < 0.001 rupees).\n",
    "\n",
    "**Primary and Secondary Metrics**:\n",
    "- **Primary**: Accuracy of predicting the first app (90% target).\n",
    "- **Secondary**: Precision, recall, F1-score for user segments; prediction latency; system availability; cost per prediction.\n",
    "\n",
    "**Handling Ignored Suggestions**:\n",
    "- Log ignored predictions as feedback.\n",
    "- Use feedback to retrain models, adjusting features or weights.\n",
    "- Explore alternative suggestions based on user choices.\n",
    "\n",
    "#### Data Management\n",
    "\n",
    "**Overview**: Data management involves collecting, storing, and processing real-time and historical data to support ML predictions while ensuring scalability and privacy.\n",
    "\n",
    "**Types of Data**:\n",
    "- **User Behavior**: Apps opened, timestamps, interaction patterns.\n",
    "- **Contextual Signals**: Location (city/pin code), device status (battery, network).\n",
    "- **Historical Patterns**: Long-term app usage trends.\n",
    "\n",
    "**Data Ingestion and Storage**:\n",
    "- **Real-Time Data**:\n",
    "  - Ingest using Apache Kafka or Amazon Kinesis ([Amazon Kinesis](https://aws.amazon.com/kinesis/)).\n",
    "  - Store in Amazon DynamoDB ([Amazon DynamoDB](https://aws.amazon.com/dynamodb/)) for fast, single-digit millisecond access.\n",
    "  - Retention: < 24 hours for immediate predictions.\n",
    "- **Historical Data**:\n",
    "  - Store in Amazon S3 ([Amazon S3](https://aws.amazon.com/s3/)) for cost-effective, durable storage.\n",
    "  - Use AWS Glue ([AWS Glue](https://aws.amazon.com/glue/)) for data cataloging and partitioning (e.g., by date or user ID).\n",
    "\n",
    "**Why These Choices?**:\n",
    "- **DynamoDB**: Offers low-latency access, ideal for real-time predictions.\n",
    "- **S3**: Scales for large datasets at low cost.\n",
    "- **Glue**: Automates ETL tasks, simplifying data preparation.\n",
    "\n",
    "**Data Anonymization**:\n",
    "- Hash user IDs to prevent identification.\n",
    "- Aggregate location data to city/pin code level.\n",
    "- Remove personally identifiable information (PII).\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[User Device] -->|App Usage Data| B[Kinesis Stream]\n",
    "    B -->|Real-Time Data| C[DynamoDB]\n",
    "    B -->|Batch Data| D[S3]\n",
    "    D -->|Catalog & Partition| E[AWS Glue]\n",
    "    C -->|Real-Time Features| F[Feature Engineering]\n",
    "    D -->|Historical Features| F\n",
    "```\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "**Overview**: Feature engineering transforms raw data into inputs for ML models, focusing on both real-time and batch processing.\n",
    "\n",
    "**Key Features**:\n",
    "- **Time Since Last App Usage**: Time elapsed since the app was last opened.\n",
    "- **App Switch Patterns**: Frequency and sequence of app transitions.\n",
    "- **Session Duration**: Average time spent in an app.\n",
    "- **Location**: City/pin code of the user.\n",
    "- **Device Context**: Battery level, network type.\n",
    "- **Historical Usage Frequency**: App usage frequency in similar contexts.\n",
    "\n",
    "**Processing**:\n",
    "- **Real-Time Features**: Processed via AWS Lambda ([AWS Lambda](https://aws.amazon.com/lambda/)) for immediate availability.\n",
    "- **Batch Features**: Computed using PySpark for ranking and aggregation.\n",
    "- **Sequential Data**: Modeled with RNNs, LSTMs, or transformers for temporal patterns.\n",
    "\n",
    "**Example: Calculating Features with PySpark**\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, unix_timestamp, current_timestamp\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"AppUsageFeatures\").getOrCreate()\n",
    "\n",
    "# Load data from S3\n",
    "df = spark.read.parquet(\"s3://my-bucket/app_usage_data.parquet\")\n",
    "\n",
    "# Calculate time since last app usage\n",
    "df_with_features = df.groupBy(\"user_id\", \"app_id\").agg(\n",
    "    (unix_timestamp(current_timestamp()) - unix_timestamp(max(\"timestamp\"))).alias(\"time_since_last_usage\")\n",
    ")\n",
    "\n",
    "# Save features to S3\n",
    "df_with_features.write.parquet(\"s3://my-bucket/features/\")\n",
    "```\n",
    "\n",
    "**Sequential Data Processing**:\n",
    "- Use transformers or RNNs/LSTMs for app usage sequences.\n",
    "- Limit sequence length to ensure low-latency inference.\n",
    "\n",
    "#### ML Pipeline Development\n",
    "\n",
    "**Overview**: The ML pipeline automates data versioning, training, validation, and deployment, ensuring reproducibility and scalability.\n",
    "\n",
    "**Key Steps**:\n",
    "1. **Data Versioning**: Use S3 object versioning to track data changes.\n",
    "2. **Training**: Train models on Amazon SageMaker ([Amazon SageMaker](https://aws.amazon.com/sagemaker/)) with spot instances for cost savings.\n",
    "3. **Validation**: Use a 30-day time series split to achieve 90% accuracy.\n",
    "4. **Model Registry**: Track model versions for deployment and rollback.\n",
    "5. **Deployment**: Deploy models as SageMaker endpoints for real-time inference.\n",
    "\n",
    "**Automation**:\n",
    "- AWS Step Functions ([AWS Step Functions](https://aws.amazon.com/step-functions/)) orchestrate retraining if accuracy drops below 85%.\n",
    "- Example: Daily performance checks trigger training jobs.\n",
    "\n",
    "**Example: SageMaker Pipeline**\n",
    "```python\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import TrainingStep, ProcessingStep\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import Processor\n",
    "\n",
    "# Define processing step\n",
    "processor = Processor(\n",
    "    image_uri=\"my-processing-image\",\n",
    "    role=\"arn:aws:iam::account-id:role/SageMakerRole\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1\n",
    ")\n",
    "step_process = ProcessingStep(\n",
    "    name=\"FeatureEngineering\",\n",
    "    processor=processor,\n",
    "    inputs=[ProcessingInput(source=\"s3://my-bucket/raw_data\", destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\")]\n",
    ")\n",
    "\n",
    "# Define training step\n",
    "estimator = Estimator(\n",
    "    image_uri=\"my-training-image\",\n",
    "    role=\"arn:aws:iam::account-id:role/SageMakerRole\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\"\n",
    ")\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainModel\",\n",
    "    estimator=estimator,\n",
    "    inputs={\"train\": TrainingInput(s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train_data\"].S3Output.S3Uri)}\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = Pipeline(name=\"AppPredictionPipeline\", steps=[step_process, step_train])\n",
    "pipeline.upsert(role_arn=\"arn:aws:iam::account-id:role/SageMakerRole\")\n",
    "```\n",
    "\n",
    "**Flowchart: ML Pipeline**\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Data Ingestion] --> B[Feature Engineering]\n",
    "    B --> C[Model Training]\n",
    "    C --> D[Model Validation]\n",
    "    D --> E[Model Registry]\n",
    "    E --> F[Model Deployment]\n",
    "    F --> G[Real-time Inference]\n",
    "    G --> H[Feedback Loop]\n",
    "    H --> B\n",
    "```\n",
    "\n",
    "**Retraining Triggers**:\n",
    "- Monitor accuracy on a holdout set or user feedback.\n",
    "- Retrain if accuracy < 85%, automated via Step Functions.\n",
    "\n",
    "#### Model Selection and Evaluation\n",
    "\n",
    "**Overview**: Model selection balances speed, accuracy, and data type. Evaluation ensures the 90% accuracy target.\n",
    "\n",
    "**Model Options**:\n",
    "- **LightGBM**: Fast, low memory, ideal for tabular data; less effective for sequences.\n",
    "- **XGBoost**: Slower but interpretable; similar limitations for sequences.\n",
    "- **Transformers/RNNs/LSTMs**: Excellent for sequential data but resource-intensive, requiring optimization for latency.\n",
    "\n",
    "**Evaluation**:\n",
    "- Use a 30-day time series split for validation.\n",
    "- Primary metric: Accuracy (90% target).\n",
    "- Secondary metrics: Precision, recall, F1-score; latency; cost.\n",
    "\n",
    "**Trade-offs**:\n",
    "- **LightGBM**: Speed vs. limited sequential modeling.\n",
    "- **Transformers**: Sequential accuracy vs. high resource use and latency.\n",
    "\n",
    "#### Deployment and Inference\n",
    "\n",
    "**Overview**: Deployment involves setting up real-time endpoints for low-latency inference, with feedback loops for improvement.\n",
    "\n",
    "**Deployment Steps**:\n",
    "- Deploy models using SageMaker endpoints.\n",
    "- Use API Gateway for request handling and Lambda for preprocessing.\n",
    "- Example: Deploying a model:\n",
    "```python\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    model_data=\"s3://my-bucket/model.tar.gz\",\n",
    "    role=\"arn:aws:iam::account-id:role/SageMakerRole\",\n",
    "    image_uri=\"my-inference-image\"\n",
    ")\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.m5.large\")\n",
    "```\n",
    "\n",
    "**Offline Support**:\n",
    "- Cache models and features on-device.\n",
    "- Sync with server when online.\n",
    "\n",
    "**A/B Testing and Canary Deployment**:\n",
    "- **A/B Testing**: Split traffic between current and new models to compare performance.\n",
    "- **Canary Deployment**: Roll out new models to a small user subset, monitoring before full deployment.\n",
    "\n",
    "#### Advanced Topics\n",
    "\n",
    "**Federated Learning**:\n",
    "- Trains models on-device, preserving privacy.\n",
    "- Advantage: No raw data sharing.\n",
    "- Challenge: Complex implementation, device resource constraints.\n",
    "\n",
    "**Edge Computing**:\n",
    "- Runs inference on-device for low latency.\n",
    "- Advantage: Reduced bandwidth usage.\n",
    "- Challenge: Increased device load, frequent model updates.\n",
    "\n",
    "#### Practical Application: Homework Assignment\n",
    "\n",
    "**Task**: Design an ML system to minimize purchase time on an e-commerce site.\n",
    "\n",
    "**Approach**:\n",
    "- **Problem**: Reduce time from landing to purchase.\n",
    "- **Factors**: User behavior (pages visited, cart additions), site design, personalization.\n",
    "- **Data**: Session data, user demographics, product data.\n",
    "- **ML Model**: Predict purchase likelihood/time; use recommendations/offers.\n",
    "- **System Design**: Similar to app prediction, with real-time data ingestion (Kinesis), feature engineering (Lambda, PySpark), training/deployment (SageMaker), and feedback loops.\n",
    "\n",
    "**Example Workflow**:\n",
    "- Collect session data (e.g., pages visited, time spent).\n",
    "- Engineer features (e.g., time to cart addition, product popularity).\n",
    "- Train a model to predict purchase likelihood.\n",
    "- Deploy for real-time recommendations (e.g., personalized offers).\n",
    "\n",
    "#### Summary\n",
    "\n",
    "These notes cover designing an ML system for predicting iPhone app usage, addressing data management, feature engineering, model selection, deployment, and advanced topics like federated learning. AWS services (SageMaker, DynamoDB, Kinesis) ensure scalability and low latency, while privacy and cost-effectiveness are prioritized. The homework assignment extends these principles to e-commerce, emphasizing practical application. For further details or specific topics, please provide feedback or questions.\n",
    "\n",
    "**Engagement**: If you need more details on any section (e.g., specific AWS service usage, code examples, or e-commerce system design), let me know, and I can expand further. I will continue providing detailed notes until you request to exit.\n",
    "\n",
    "### Key Citations\n",
    "- [Amazon SageMaker - Build, Train, Deploy ML Models](https://aws.amazon.com/sagemaker/)\n",
    "- [Amazon Kinesis - Real-Time Data Streaming](https://aws.amazon.com/kinesis/)\n",
    "- [Amazon DynamoDB - Fast NoSQL Database](https://aws.amazon.com/dynamodb/)\n",
    "- [Amazon S3 - Scalable Object Storage](https://aws.amazon.com/s3/)\n",
    "- [AWS Glue - Managed ETL Service](https://aws.amazon.com/glue/)\n",
    "- [AWS Lambda - Serverless Compute Service](https://aws.amazon.com/lambda/)\n",
    "- [AWS Step Functions - Workflow Orchestration](https://aws.amazon.com/step-functions/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
