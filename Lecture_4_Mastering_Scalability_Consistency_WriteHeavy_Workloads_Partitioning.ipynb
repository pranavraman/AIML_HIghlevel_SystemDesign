{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering Scalability in System Design: Consistency, Write-Heavy Workloads, Partitioning, and Real-World Applications\n",
    "\n",
    "## Table of Contents\n",
    "1. [Flowchart for Write Request Process](#flowchart-for-write-request-process)\n",
    "2. [Consistency Problem](#consistency-problem)\n",
    "3. [Acknowledgement Messages for Master-Slave Replication](#acknowledgement-messages-for-master-slave-replication)\n",
    "4. [Replica Distribution in ML Models](#replica-distribution-in-ml-models)\n",
    "5. [Multi-threaded Writing of Replica](#multi-threaded-writing-of-replica)\n",
    "6. [Replica Distribution Among Slave Nodes](#replica-distribution-among-slave-nodes)\n",
    "7. [Handling Write Heavy Cases](#handling-write-heavy-cases)\n",
    "8. [Sharding and Hash Partitioning](#sharding-and-hash-partitioning)\n",
    "9. [Handling Hot Spots](#handling-hot-spots)\n",
    "10. [Benchmarking Server Capacity](#benchmarking-server-capacity)\n",
    "11. [Like Counting Mechanism](#like-counting-mechanism)\n",
    "12. [SQS vs Kafka](#sqs-vs-kafka)\n",
    "13. [YouTube Video Upload Costs](#youtube-video-upload-costs)\n",
    "\n",
    "---\n",
    "\n",
    "## Flowchart for Write Request Process\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User] --> B[Write Request]\n",
    "    B --> C[API Gateway]\n",
    "    C --> D[API Server]\n",
    "    D --> E[Master DB]\n",
    "    E --> F[Load Balancer]\n",
    "    F --> G(Replica 1)\n",
    "    F --> H(Replica 2)\n",
    "    F --> I(Replica 3)\n",
    "```\n",
    "### Explanation:\n",
    "\n",
    "- **User** sends a write request (e.g., editing a Wikipedia article).\n",
    "- **API Gateway** interacts with the incoming requests and directs them to the appropriate service.\n",
    "- **API Server** processes the incoming request and sends the data to the **Master Database (DB)**.\n",
    "- The **Load Balancer** distributes the load to multiple **Slave Databases (DBs)** for read operations.\n",
    "\n",
    "In context, when you're writing something on Wikipedia, this data is stored in the Master DB, and it's replicated in the slave machines for read operations, ensuring data redundancy and availability.\n",
    "\n",
    "---\n",
    "\n",
    "## Consistency Problem\n",
    "\n",
    "### Scenario:\n",
    "\n",
    "When a user writes an article on Wikipedia and shares its link immediately, the link may not work instantly. This happens because the backup has not been created yet, which results in a **Consistency Problem**.\n",
    "\n",
    "**Definition:**\n",
    "- **Consistency** in distributed systems means that all nodes see the same data at the same time. In this case, the inconsistency arises when the newly created data has not yet propagated to the replicas.\n",
    "\n",
    "### Key Points:\n",
    "- There is often a lag between the Master and Slave databases.\n",
    "- This inconsistency creates a poor user experience when immediate feedback is expected, such as having friends not seeing a Facebook post shortly after writing it. \n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledgement Messages for Master-Slave Replication\n",
    "\n",
    "### Question: Before sending the data from master to slave, if the master crashes, what to do?\n",
    "\n",
    "This scenario is known as a **Data Integrity Issue**.\n",
    "\n",
    "### Solution:\n",
    "To mitigate this, we need an acknowledgment message confirming that the data has been written successfully to at least one Slave machine before accepting read requests.\n",
    "\n",
    "### Explanation:\n",
    "- This mechanism ensures that clients only read data that is known to be safely replicated, thus maintaining consistency.\n",
    "- It's a trade-off between latency (speed of responses) and safety (ensuring correctness even during failures).\n",
    "\n",
    "### Example:\n",
    "- If a user writes an article that is particularly important, they can be informed of slight delays in availability while the system confirms the writing completion.\n",
    "\n",
    "---\n",
    "\n",
    "## Replica Distribution in ML Models\n",
    "\n",
    "### Explanation:\n",
    "Yes, machine learning models can also be replicated across multiple slave machines. \n",
    "\n",
    "**Reasons:**\n",
    "- **Load Balancing**: Distributes inference requests across multiple replicas, preventing any single machine from becoming a bottleneck.\n",
    "- **Fault Tolerance**: If one replica fails, others can still serve requests.\n",
    "- **Latency Reduction**: Allows faster responses by bringing data closer to where it's needed geographically.\n",
    "\n",
    "### Example:\n",
    "In a real-world scenario, if a company is using a recommendation model for their e-commerce platform, they may want to replicate the model across several regions to improve response times.\n",
    "\n",
    "---\n",
    "\n",
    "## Multi-threaded Writing of Replica\n",
    "\n",
    "### Question: Does writing the replica to a slave machine occur in a multi-threaded manner? \n",
    "\n",
    "**Explanation:**\n",
    "Yes, writing replicas is typically managed using multi-threading for efficiency. \n",
    "\n",
    "### Details:\n",
    "- Multi-threaded operations allow simultaneous writing to multiple slave databases, substantially enhancing throughput.\n",
    "- In Python, this can be accomplished using libraries like `threading`or `concurrent.futures` for parallel task management.\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def write_to_slave(slave_db, data):\n",
    "    # Function to write data to a slave database\n",
    "    pass\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    for slave in slave_dbs:\n",
    "        executor.submit(write_to_slave, slave, data)\n",
    "```\n",
    "\n",
    "### Benefits:\n",
    "- Improved performance, as multiple requests can be handled concurrently.\n",
    "\n",
    "---\n",
    "\n",
    "## Replica Distribution Among Slave Nodes\n",
    "\n",
    "### Question: Does replication happen between slave to slave?\n",
    "\n",
    "**Answer:**\n",
    "Generally, the replication process is typically **Master-to-Slave** for consistency.\n",
    "\n",
    "### Reasoning:\n",
    "- Slave databases are primarily used for read operations and are updated from the Master. \n",
    "\n",
    "### Process:\n",
    "1. The Master DB sends changes to the Slave DBs.\n",
    "2. Some systems, however, can be set up to allow **Asynchronous Replication** between slaves to ensure that read operations remain efficient.\n",
    "\n",
    "### Conclusion:\n",
    "- While copying data from Slave to Slave can introduce complexity and potential inconsistency, it can also help distribute load among read replicas.\n",
    "\n",
    "---\n",
    "\n",
    "## Handling Write Heavy Cases\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "In scenarios where there are frequent writing operations (like in order processing or high-frequency trading), handling the overwhelming number of write requests becomes critical.\n",
    "\n",
    "**Flowchart for Write-Heavy Cases:**\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User] --> B[Write Request]\n",
    "    B --> C[API Gateway]\n",
    "    C --> D[API Server]\n",
    "    D --> E[Sharded DBs]\n",
    "    E --> F[Load Balancer]\n",
    "    F --> G(Replica 1)\n",
    "    F --> H(Replica 2)\n",
    "    F --> I(Replica 3)\n",
    "```\n",
    "### Description:\n",
    "- Write requests go through an API Gateway to multiple API Servers and then get directed to Sharded Databases, where data is managed through vertical or horizontal partitioning.\n",
    "\n",
    "### Sharding:\n",
    "- **Definition**: Sharding is the process of splitting a dataset into smaller, more manageable parts called \"shards\".\n",
    "- **Example**: For instance, you could shard a customer database alphabetically (A-C, D-M, etc.).\n",
    "\n",
    "### Why Shard?\n",
    "- To reduce the load on a single database and improve performance by distributing the data across multiple machines.\n",
    "\n",
    "---\n",
    "\n",
    "## Sharding and Hash Partitioning\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "**Hash Partitioning**: This technique distributes data evenly across partitions by using a hash function.\n",
    "\n",
    "### Example:\n",
    "- If you have user IDs, you could assign each user to a partition based on the hash value of their user ID (modulus with the number of partitions).\n",
    "\n",
    "### Benefits:\n",
    "- Even distribution of requests and minimal hot-spot creation, allowing for smoother performance under load.\n",
    "\n",
    "### Range vs. Hash Partitioning:\n",
    "- **Range Partitioning**: Data is partitioned based on specific ranges (e.g., A-C, D-M). Risk of hot spots if many records fall within certain ranges.\n",
    "- **Hash Partitioning**: Provides more even distribution, reducing the risk of hot spots.\n",
    "\n",
    "---\n",
    "\n",
    "## Handling Hot Spots\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "**Hot spots** occur when a few database partitions receive a significant amount of reads/writes compared to others, which can lead to performance degradation.\n",
    "\n",
    "### Strategy to Handle Hot Spots:\n",
    "1. **Monitoring**: Use tools like Grafana and Prometheus to monitor user activity.\n",
    "2. **Isolation**: Shift hot spot users to dedicated machines to manage load.\n",
    "\n",
    "### Flowchart for Handling Hot Spots:\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User Requests] --> B[Hot Spot Detection]\n",
    "    B --> C[Move to Isolated DB]\n",
    "    C --> D[Scale Up Replicas]\n",
    "```\n",
    "This flow allows you to manage hot spots efficiently by isolating users causing excessive load.\n",
    "\n",
    "---\n",
    "\n",
    "## Benchmarking Server Capacity\n",
    "\n",
    "**Question: How to benchmark a serverâ€™s capacity for workload?**\n",
    "\n",
    "### Explanation:\n",
    "To determine how many instances can run on a server, follow these steps:\n",
    "1. **Direct Testing**: Start instances incrementally while monitoring for CPU, memory, and disk usage.\n",
    "2. **Load Testing Tools**: Use tools like Apache JMeter or locust.io to simulate load and observe point of failure.\n",
    "\n",
    "### Solution:\n",
    "- Whenever a new instance is needed, transitioning to cloud resources may be a more efficient way of scaling.\n",
    "\n",
    "### Trade-off:\n",
    "- **Cost vs. Performance**: High costs may not be justifiable if performance can be achieved at lower costs or different configurations.\n",
    "\n",
    "---\n",
    "\n",
    "## Like Counting Mechanism\n",
    "\n",
    "### Question: Is it a good idea to count likes through API requests from the server?\n",
    "\n",
    "### Explanation:\n",
    "It's generally **not efficient** for server resources to count likes in real-time due to the ephemeral high volume of requests.\n",
    "\n",
    "### Flowchart:\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User Likes Video] --> B[API Gateway]\n",
    "    B --> C[Rate Limiter]\n",
    "    C --> D[Workers Queue]\n",
    "    D --> E[Count Likes]\n",
    "    E --> F[Update DB]\n",
    "```\n",
    "\n",
    "### Techniques Employed:\n",
    "1. **Delegation**: Move the counting to worker nodes to handle asynchronously.\n",
    "2. **Queue Systems**: Using Kafka queues for asynchrony, ensuring that likes do not overwhelm database operations.\n",
    "\n",
    "---\n",
    "\n",
    "## SQS vs Kafka\n",
    "\n",
    "### Comparison:\n",
    "\n",
    "| Feature                | SQS                   | Kafka                 |\n",
    "|------------------------|-----------------------|-----------------------|\n",
    "| Message Type           | One type              | Multiple types        |\n",
    "| Persistence            | Non-persistent        | Persistent            |\n",
    "| Ordering               | FIFO                   | Partially Ordered    |\n",
    "| Throughput             | Limited                | High                  |\n",
    "| Price                  | Low                    | Moderate               |\n",
    "\n",
    "### Explanation:\n",
    "- **SQS (Simple Queue Service)** is simpler and cheaper, suitable for basic queuing needs, while **Kafka** is more complex but provides more advanced functionalities, such as real-time analytics and message persistence.\n",
    "\n",
    "---\n",
    "\n",
    "## YouTube Video Upload Costs\n",
    "\n",
    "### Flowchart for Video Upload:\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User Uploads Video] --> B[Video Service]\n",
    "    B --> C[Post Service]\n",
    "    C --> D[S3 Storage]\n",
    "    D --> E[Database]\n",
    "```\n",
    "\n",
    "### Cost Breakdown:\n",
    "\n",
    "| Cost Type          | Description                                   |\n",
    "|--------------------|-----------------------------------------------|\n",
    "| Incoming Costs      | Costs to upload data to S3                   |\n",
    "| Storage Costs       | Ongoing costs of storing video files         |\n",
    "| Outgoing Costs      | Costs associated with video streaming         |\n",
    "\n",
    "### Explanation:\n",
    "As the streaming service grows, companies have to manage incoming, storage, and outgoing costs effectively. Efficiently managing these costs is critical for profitability as user interaction increases.\n",
    "\n",
    "---\n",
    "\n",
    "This concludes the detailed notes for the scaling problems in system design."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
